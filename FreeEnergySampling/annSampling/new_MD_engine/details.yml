RUN SIM:
  ./ABP.py (should modify in.ABP)
  ./ABF.py (should modify in.ABF)

IMPLM NOTE1:
  1. To implement free energy sampling method, we need to take advantage of the mdEngine but "not to modify" the engine itself.
  2. Instead we use a python advanced concept called "decorator" to decorate the mdEngine so as to perform free energy sampling method with the core part of engine being un-modified.
  3. The value of the rightmost bin = the value of the leftmost bin so as to retain PBC
  4. 

IMPLM NOTE:

NOMENCLATURE:
  ABF = adpative biasing "force"
  ABP = adpative biasing "potential"

SIM NOTE:
  1. gamma=2 for 1D, gamma=2 for 2D so as to reach thermal equilibrium as time_step=0.005 (0.5 can be another choice) {1 / (100 * 0.005) = 2}
  2. higher deviation --> add regularization --> better result (0.00015~0.00025)
  3. sigmoid > tanh > relu
  4. mass 0.1, Temperature 4, time_length 16M, interval 4M or 6M
  
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

USEFUL RESOURCE:
  1. https://stats.stackexchange.com/questions/110564/why-do-people-like-smooth-data
  2. https://www2.ph.ed.ac.uk/~dmarendu/MVP/MVP03.pdf (key for the vva of my thesis)
  3. https://lammps.sandia.gov/threads/msg07840.html  (T, P fluctuation for langevin)
  4. https://medium.com/@chih.sheng.huang821 (ML Background)
  5. https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E4%BB%8B%E7%B4%B9-8e49f7f5be29 (ML intro)
  6. http://kirilllykov.github.io/blog/2012/10/13/writing-fixes-for-lammps/ (write fix for lammps)
  7. https://www.quora.com/What-does-it-mean-that-we-dont-really-understand-what-happens-in-neural-networks
  8. https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E6%95%B8%E5%AD%B8-%E4%B8%89-%E6%A2%AF%E5%BA%A6%E6%9C%80%E4%BD%B3%E8%A7%A3%E7%9B%B8%E9%97%9C%E7%AE%97%E6%B3%95-gradient-descent-optimization-algorithms-b61ed1478bd7 (activation)
  9. http://umdberg.pbworks.com/w/page/49681668/Boltzmann%20distribution%20and%20Gibbs%20free%20energy
 10. https://scitechvista.nat.gov.tw/c/sTWR.htm  (FREE E)

STATISCAL ANALYSIS:
  https://www.ycc.idv.tw/confusion-matrix.html (Confusion Matrix)

PCA:
  http://arbu00.blogspot.com/2017/02/6-principal-component-analysispca.html
  是一種特徵提取的技術，利用特徵降維來避免因維度災難所造成的過度適合(Overfitting)現象
  PCA著眼在高維度的數據，"最大化變異數"並投影到與原數據及相同維數或較低維數的"新特徵子空間"。新特徵子空間的正交軸即是"主成分"。
  eigenvalue就是變異量(variance)，eigenvector就是讓資料投影下去會有最大變異量的投影軸。
  
